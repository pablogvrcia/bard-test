{"cells":[{"cell_type":"markdown","metadata":{"id":"k4K8TRVBAnIr"},"source":["## LAB 2 ML 2023-24. - OPTIONAL TASKS FOR COURSE PROJECT (1 POINT).\n","\n","FILL UP THIS BOX WITH YOUR DETAILS\n","\n","**NAME AND NIP**:\n","Anyiel Fernandes Araujo 779374\n","Pablo Garcia Garcia 781020"]},{"cell_type":"markdown","metadata":{"id":"QHnVupBBn9eR"},"source":["### This task is built on an oficial Detectron2 Tutorial for object detection, to run inference on images or videos, with an existing detectron2 model\n","\n","### Detectron2 Beginner's Tutorial\n","https://detectron2.readthedocs.io/en/latest/tutorials/getting_started.html\n","\n","© Copyright 2019-2020, detectron2 contributors Revision 1ad5759b.\n","\n","\n","### Different from the other notebooks in this Lab, this one uses pytorch framework, so you can see an example with this other framework.\n"]},{"cell_type":"markdown","metadata":{"id":"vM54r6jlKTII"},"source":["# Install detectron2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FsePPpwZSmqt"},"outputs":[],"source":["!python -m pip install pyyaml==5.1\n","import sys, os, distutils.core\n","# Note: This is a faster way to install detectron2 in Colab, but it does not include all functionalities (e.g. compiled operators).\n","# See https://detectron2.readthedocs.io/tutorials/install.html for full installation instructions\n","!git clone 'https://github.com/facebookresearch/detectron2'\n","dist = distutils.core.run_setup(\"./detectron2/setup.py\")\n","!python -m pip install {' '.join([f\"'{x}'\" for x in dist.install_requires])}\n","sys.path.insert(0, os.path.abspath('./detectron2'))\n","\n","# Properly install detectron2. (Please do not install twice in both ways)\n","# !python -m pip install 'git+https://github.com/facebookresearch/detectron2.git'"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZyAvNCJMmvFF"},"outputs":[],"source":["# Some basic setup:\n","# Setup detectron2 logger\n","import detectron2\n","from detectron2.utils.logger import setup_logger\n","setup_logger()\n","\n","# import some common libraries\n","import numpy as np\n","import os, json, cv2, random\n","from google.colab.patches import cv2_imshow\n","\n","# import some common detectron2 utilities\n","from detectron2 import model_zoo\n","from detectron2.engine import DefaultPredictor\n","from detectron2.config import get_cfg\n","from detectron2.utils.visualizer import Visualizer\n","from detectron2.data import MetadataCatalog, DatasetCatalog"]},{"cell_type":"markdown","metadata":{"id":"Vk4gID50K03a"},"source":["# Run a pre-trained detectron2 model"]},{"cell_type":"markdown","metadata":{"id":"JgKyUL4pngvE"},"source":["We first download an image from the COCO dataset:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dq9GY37ml1kr"},"outputs":[],"source":["!wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n","im = cv2.imread(\"./input.jpg\")\n","cv2_imshow(im)"]},{"cell_type":"markdown","metadata":{"id":"uM1thbN-ntjI"},"source":["Then, we create a detectron2 config and a detectron2 `DefaultPredictor` to run inference on this image."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HUjkwRsOn1O0"},"outputs":[],"source":["cfg = get_cfg()\n","# add project-specific config (e.g., TensorMask) here if you're not running a model in detectron2's core library\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.5  # set threshold for this model\n","# Find a model from detectron2's model zoo. You can use the https://dl.fbaipublicfiles... url as well\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-InstanceSegmentation/mask_rcnn_R_50_FPN_3x.yaml\")\n","predictor = DefaultPredictor(cfg)\n","outputs = predictor(im)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"7d3KxiHO_0gb"},"outputs":[],"source":["# look at the outputs. See https://detectron2.readthedocs.io/tutorials/models.html#model-output-format for specification\n","print(outputs[\"instances\"].pred_classes)\n","print(outputs[\"instances\"].pred_boxes)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8IRGo8d0qkgR"},"outputs":[],"source":["# We can use `Visualizer` to draw the predictions on the image.\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(out.get_image()[:, :, ::-1])"]},{"cell_type":"markdown","metadata":{"id":"m6J5v60lD_8H"},"source":["### QUESTION 1:\n","Change two parameters in this CFG and explain what you have changed and what you expect to change in the output, or what you see is different analyzing the new predictions.\n","\n","For example, find the parameter that allows more detections although less confident ones, and change the model used for the predictions (You can find plenty of models from detectron2's model zoo https://github.com/facebookresearch/detectron2/blob/main/MODEL_ZOO.md)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"tCDxixG7eKj5"},"outputs":[],"source":["# With this print you can take a look to all the configuration parameters set for this particular inference task\n","# if you want to explore something else than the \"basic\" changes suggested above (threshold and model used)\n","print(cfg)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6Zf20ompFEAh"},"outputs":[],"source":["# put here your snippet of code to run inference with your modification 1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H9TzCoTvGR5I"},"outputs":[],"source":["# put here your snippet of code to run inference with your modification 2"]},{"cell_type":"markdown","metadata":{"id":"jDmIoETuFDzl"},"source":["ANSWER 1: [YOUR ANSWER HERE] (max 5 lines)"]},{"cell_type":"markdown","metadata":{"id":"ZRQNHNaBC8Yt"},"source":["### QUESTION 2:\n","After running the model on your own *image test set* (10 images that you take with your phone. 5 that you thought are *easy* for this model. 5 that you thought would be difficult for the model).\n","\n","Evaluate **qualitatively (no need to label your images)** and **discuss results**. What works well or not? Why? What works or doesn’t as you expected?\n","\n","NOTE: careful if your image has different size than the example, no need to change anything in CFG only re-launch all the code (visualizer included) to take the right dimensions in the display"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DB7HR5BSmy3y"},"outputs":[],"source":["# put here your snippet of code to run the inference on your test images and display the results"]},{"cell_type":"markdown","metadata":{"id":"_JROHfpRDmwE"},"source":["ANSWER 2: [YOUR ANSWER HERE] (max 10 lines)"]},{"cell_type":"markdown","metadata":{"id":"oKBbjnLw5GGG"},"source":["# Other types of builtin models in Detectron2\n","\n","If you are curious, detectron2 provides a very powerful platform, with additional models other than simple detection, these are some other examples with existing models"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"GYJrlXZC5M-J"},"outputs":[],"source":["# Inference with a keypoint detection model\n","cfg = get_cfg()   # get a fresh new config\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\"))\n","cfg.MODEL.ROI_HEADS.SCORE_THRESH_TEST = 0.7  # set threshold for this model\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-Keypoints/keypoint_rcnn_R_50_FPN_3x.yaml\")\n","predictor = DefaultPredictor(cfg)\n","outputs = predictor(im)\n","v = Visualizer(im[:,:,::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","out = v.draw_instance_predictions(outputs[\"instances\"].to(\"cpu\"))\n","cv2_imshow(out.get_image()[:, :, ::-1])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"roTj1N9F5uJ5"},"outputs":[],"source":["# Inference with a panoptic segmentation model\n","cfg = get_cfg()\n","cfg.merge_from_file(model_zoo.get_config_file(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\"))\n","cfg.MODEL.WEIGHTS = model_zoo.get_checkpoint_url(\"COCO-PanopticSegmentation/panoptic_fpn_R_101_3x.yaml\")\n","predictor = DefaultPredictor(cfg)\n","panoptic_seg, segments_info = predictor(im)[\"panoptic_seg\"]\n","v = Visualizer(im[:, :, ::-1], MetadataCatalog.get(cfg.DATASETS.TRAIN[0]), scale=1.2)\n","out = v.draw_panoptic_seg_predictions(panoptic_seg.to(\"cpu\"), segments_info)\n","cv2_imshow(out.get_image()[:, :, ::-1])"]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[{"file_id":"1a2H1ruI5SgjXRihGE4A6xsAXaGb4WM3k","timestamp":1638103554059},{"file_id":"16jcaJoc6bCFAQ96jDe2HwtXj7BMD_-m5","timestamp":1637883224085}]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"nbformat":4,"nbformat_minor":0}
